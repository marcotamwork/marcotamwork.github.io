[{"content":"","date":"28 June 2024","permalink":"/tags/azure/","section":"Tags","summary":"","title":"Azure"},{"content":"","date":"28 June 2024","permalink":"/tags/iac/","section":"Tags","summary":"","title":"IaC"},{"content":"","date":"28 June 2024","permalink":"/series/iac-on-3-tier-architecture-through-terraform-in-azure/","section":"Series","summary":"","title":"IaC on 3-Tier architecture through Terraform in Azure"},{"content":"Introduction # Welcome to the second part of our guide on deploying a 3-tier AWS infrastructure with Terraform! In this section, we‚Äôll focus on setting up the backbone of your architecture. This includes creating the Virtual Network (VNet) to organize your subnets, setting up a Resource Group to keep everything neatly grouped, configuring a Network Security Group (NSG) to control traffic, and using Key Vault to securely manage sensitive data. By the end of this part, you‚Äôll have a solid, secure foundation ready to support the rest of your infrastructure. Let‚Äôs get started!\nArchitecture # Creating Cloud Resource with Terraform # Variables and Data # Variables in Terraform act in an important role, as it increase security and reusability, preventing hardcoding values and exposure on sensitive data, and utilizing the same Terraform template across multiple environments by easily editing values of variables.\nSpecifying their values in variable definitions files(with a filename ending in either .tfvars or .tfvars.json) helps to set lots of variables in different environments. So we divide 1 .tfvar file to set the value of variable per environment and 1 .tf file to declare input variables.\nNote: We can specify file by environment on the terraform command line with flag \u0026quot;-var-file\u0026quot;. The command will be shown later.\n# test.tfvars environment = \u0026#34;test\u0026#34; location = \u0026#34;East Asia\u0026#34; # variable.tf variable \u0026#34;environment\u0026#34; { type = string } variable \u0026#34;location\u0026#34; { type = string } More, we use terraform data to get current Azure subscription and current configuration of AzureRM provider.\n# data.tf data \u0026#34;azurerm_subscription\u0026#34; \u0026#34;current\u0026#34; {} data \u0026#34;azurerm_client_config\u0026#34; \u0026#34;current\u0026#34; {} Note: Data sources serve as a bridge between the current infrastructure and the desired configuration, allowing for more dynamic and context-aware provisioning.\nResource Group # Providing a management layer that enables you to manage resources in Azure account, we create a resource group first and organize our infrastructure within the resource group. In real-world scenarios, companies often organize Resource Groups in different ways‚Äîby project, team, region, or even by resource type, like grouping all VNets together. But to keep things straightforward here, we‚Äôll stick to a single Resource Group for now. It‚Äôs a practical starting point, but remember that every organization has its own way of managing resources.\n# Resource Group resource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;project\u0026#34; { name = \u0026#34;project-rg-${var.environment}\u0026#34; location = var.location tags = { Environment = \u0026#34;${var.environment}\u0026#34; } } Virtual Network # Let‚Äôs create an Azure Virtual Network and subnets.\nVNet # This deploys a virtual network called \u0026ldquo;project-vnet-test\u0026rdquo; inside resource group \u0026ldquo;project-rg-test\u0026rdquo; with an address space of \u0026ldquo;10.0.0.0/16\u0026rdquo;, which will allow you to deploy multiple subnets in that range.\nDepending on company practices, developers might be required to use a shared VPC/VNet managed by the DevOps or cloud team to centralize network traffic control. However, since this is a demo project, we‚Äôll keep things simple and create a basic VNet.\n# vnet.tf # Create a virtual network resource \u0026#34;azurerm_virtual_network\u0026#34; \u0026#34;project\u0026#34; { name = \u0026#34;project-vnet-${var.environment}\u0026#34; address_space = [\u0026#34;10.0.0.0/16\u0026#34;] location = azurerm_resource_group.project.location resource_group_name = azurerm_resource_group.project.name tags = { Environment = \u0026#34;${var.environment}\u0026#34; } } Note: When designing a VNet, it‚Äôs important to avoid overlapping IP address ranges, especially with AKS. Overlaps can cause routing issues, so plan your CIDR blocks carefully to ensure smooth integration.\nSubnet # Building 3 subnets for AKS Node pool, Storage Account, and MySQL, we hold CIDR \u0026ldquo;10.0.2.0/24\u0026rdquo; for later defining AKS‚Äôs network profile. Subnets are then defined with address prefixes:\n\u0026ldquo;10.0.1.0/24\u0026rdquo; for AKS node pool subnet \u0026ldquo;10.0.3.0/24\u0026rdquo; for Storage subnet \u0026ldquo;10.0.4.0/24\u0026rdquo; for MySQL subnet For subnet \u0026ldquo;project-db-subnet-test\u0026rdquo;, we delegated the subnet to \u0026ldquo;Microsoft.DBforMySQL/flexibleServers\u0026rdquo; which means that only Azure Database for MySQL flexible server instances can use that subnet. Last, but not least, all subnets were added \u0026ldquo;Microsoft.Storage\u0026rdquo; for service endpoint for secure and direct connectivity to Azure Storage service.\nNote: Virtual Network (VNet) service endpoint provides secure and direct connectivity to Azure services over an optimized route over the Azure backbone network.\nNote: Subnet delegation provides full control to the customer on managing the integration of Azure services into their virtual networks.\n# vnet.tf ### CIDR \u0026#34;10.0.2.0/24\u0026#34; is delegated for AKS services # Subnet for AKS node pool resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;node_subnet\u0026#34; { name = \u0026#34;project-node-subnet-${var.environment}\u0026#34; resource_group_name = azurerm_resource_group.project.name virtual_network_name = azurerm_virtual_network.project.name address_prefixes = [\u0026#34;10.0.1.0/24\u0026#34;] service_endpoints = [\u0026#34;Microsoft.Storage\u0026#34;] } # Subnet for Storage resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;storage_subnet\u0026#34; { name = \u0026#34;project-storage-${var.environment}\u0026#34; resource_group_name = azurerm_resource_group.project.name virtual_network_name = azurerm_virtual_network.project.name address_prefixes = [\u0026#34;10.0.3.0/24\u0026#34;] service_endpoints = [\u0026#34;Microsoft.Storage\u0026#34;] } # Subnet for MySQL resource \u0026#34;azurerm_subnet\u0026#34; \u0026#34;db_subnet\u0026#34; { name = \u0026#34;project-db-subnet-${var.environment}\u0026#34; resource_group_name = azurerm_resource_group.project.name virtual_network_name = azurerm_virtual_network.project.name address_prefixes = [\u0026#34;10.0.4.0/24\u0026#34;] service_endpoints = [\u0026#34;Microsoft.Storage\u0026#34;] delegation { name = \u0026#34;fs\u0026#34; service_delegation { name = \u0026#34;Microsoft.DBforMySQL/flexibleServers\u0026#34; actions = [ \u0026#34;Microsoft.Network/virtualNetworks/subnets/join/action\u0026#34;, ] } } } Network Security Group # Security rules in network security groups enable us to filter the type of network traffic that can flow in and out of virtual network subnets and network interfaces. We create 1 NSG to filter traffic that flows in and out MySQL subnet.\nNote: When creating a Network Security Group (NSG), default security rules are automatically generated. These rules typically allow basic inbound and outbound traffic. For environments like development, UAT, or SIT, additional rules with higher priorities may need to be configured. These rules ensure that only authorized business users and developers can access these environments, maintaining proper security and isolation.\n# nsg.tf # Security Group resource \u0026#34;azurerm_network_security_group\u0026#34; \u0026#34;nsg\u0026#34; { name = \u0026#34;project-sg-${var.environment}\u0026#34; location = azurerm_resource_group.project.location resource_group_name = azurerm_resource_group.project.name security_rule { name = \u0026#34;AllowMySQL\u0026#34; priority = 100 direction = \u0026#34;Inbound\u0026#34; access = \u0026#34;Allow\u0026#34; protocol = \u0026#34;Tcp\u0026#34; source_port_range = \u0026#34;*\u0026#34; destination_port_range = \u0026#34;3306\u0026#34; source_address_prefix = \u0026#34;10.0.2.0/24\u0026#34; destination_address_prefix = \u0026#34;10.0.4.0/24\u0026#34; } tags { environment = \u0026#34;${var.environment}\u0026#34; } } resource \u0026#34;azurerm_subnet_network_security_group_association\u0026#34; \u0026#34;data\u0026#34; { subnet_id = azurerm_subnet.example.id network_security_group_id = azurerm_network_security_group.nsg.id } User Assigned Identity # We then create 1 UAI as prerequisite for MySQL server. The managed identity will be configured to MySQL server, so we can authorize UAI to MySQL database securely.\nNote: You may also create a managed identity as a standalone Azure resource. You can create a user-assigned managed identity and assign it to one or more Azure Resources.\n# uai.tf # User Assigned Identity resource \u0026#34;azurerm_user_assigned_identity\u0026#34; \u0026#34;uai\u0026#34; { name = \u0026#34;project-uai-${var.environment}\u0026#34; resource_group_name = azurerm_resource_group.project.name location = azurerm_resource_group.project.location } Key Vault # Moreover, we create Key Vault as secure store for secrets. And 2 2048-bit RSA keys will be created, separately for MySQL and Storage Account.\nNote: Premium level pricing tier adds Thales HSM (Hardware Security Modules) to Key Vault comparing to standard level pricing tier. please refer to Azure Key Vault pricing.\nNote: Access policys of key vault is nearly providing full access to UAI and user as for demo. Please adjust according to your need. Here is one example on requirement of access policy for Data encryption for Azure Database for MySQLMySQL fexible server.\n# key_vault.tf # Key Vault resource \u0026#34;azurerm_key_vault\u0026#34; \u0026#34;key\u0026#34; { name = \u0026#34;project-dbkey-${var.environment}\u0026#34; location = azurerm_resource_group.project.location resource_group_name = azurerm_resource_group.project.name enabled_for_disk_encryption = true tenant_id = data.azurerm_client_config.current.tenant_id soft_delete_retention_days = 90 # value can be between 7 and 90 (the default) days purge_protection_enabled = true # Once Purge Protection has been enabled it\u0026#39;s not possible to disable it sku_name = \u0026#34;standard\u0026#34; # refer to pricing tier, possible values are standard and premium } # Access Policy for yourself resource \u0026#34;azurerm_key_vault_access_policy\u0026#34; \u0026#34;yourself\u0026#34; { key_vault_id = azurerm_key_vault.key.id tenant_id = data.azurerm_client_config.current.tenant_id object_id = data.azurerm_client_config.current.object_id key_permissions = [ \u0026#34;Get\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;Update\u0026#34;, \u0026#34;Create\u0026#34;, \u0026#34;Import\u0026#34;, \u0026#34;Delete\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;Backup\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Decrypt\u0026#34;, \u0026#34;Encrypt\u0026#34;, \u0026#34;UnwrapKey\u0026#34;, \u0026#34;WrapKey\u0026#34;, \u0026#34;Verify\u0026#34;, \u0026#34;Sign\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Release\u0026#34;, \u0026#34;Rotate\u0026#34;, \u0026#34;GetRotationPolicy\u0026#34;, \u0026#34;SetRotationPolicy\u0026#34; ] secret_permissions = [ \u0026#34;Backup\u0026#34;, \u0026#34;Delete\u0026#34;, \u0026#34;Get\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Set\u0026#34; ] storage_permissions = [ \u0026#34;Backup\u0026#34;, \u0026#34;Delete\u0026#34;, \u0026#34;DeleteSAS\u0026#34;, \u0026#34;Get\u0026#34;, \u0026#34;GetSAS\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;ListSAS\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;RegenerateKey\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Set\u0026#34;, \u0026#34;SetSAS\u0026#34;, \u0026#34;Update\u0026#34; ] } # Access Policy for UAI resource \u0026#34;azurerm_key_vault_access_policy\u0026#34; \u0026#34;uai\u0026#34; { key_vault_id = azurerm_key_vault.key.id tenant_id = azurerm_user_assigned_identity.uai.tenant_id object_id = azurerm_user_assigned_identity.uai.principal_id key_permissions = [ \u0026#34;Get\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;Update\u0026#34;, \u0026#34;Create\u0026#34;, \u0026#34;Import\u0026#34;, \u0026#34;Delete\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;Backup\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Decrypt\u0026#34;, \u0026#34;Encrypt\u0026#34;, \u0026#34;UnwrapKey\u0026#34;, \u0026#34;WrapKey\u0026#34;, \u0026#34;Verify\u0026#34;, \u0026#34;Sign\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Release\u0026#34;, \u0026#34;Rotate\u0026#34;, \u0026#34;GetRotationPolicy\u0026#34;, \u0026#34;SetRotationPolicy\u0026#34; ] secret_permissions = [ \u0026#34;Backup\u0026#34;, \u0026#34;Delete\u0026#34;, \u0026#34;Get\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Set\u0026#34; ] storage_permissions = [ \u0026#34;Backup\u0026#34;, \u0026#34;Delete\u0026#34;, \u0026#34;DeleteSAS\u0026#34;, \u0026#34;Get\u0026#34;, \u0026#34;GetSAS\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;ListSAS\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;RegenerateKey\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Set\u0026#34;, \u0026#34;SetSAS\u0026#34;, \u0026#34;Update\u0026#34; ] } # We will add Access Policy for Storage Account later # Key resource \u0026#34;azurerm_key_vault_key\u0026#34; \u0026#34;db\u0026#34; { name = \u0026#34;project-dbkey-${var.environment}\u0026#34; key_vault_id = azurerm_key_vault.key.id key_type = \u0026#34;RSA\u0026#34; key_size = 2048 key_opts = [ \u0026#34;decrypt\u0026#34;, \u0026#34;encrypt\u0026#34;, \u0026#34;sign\u0026#34;, \u0026#34;unwrapKey\u0026#34;, \u0026#34;verify\u0026#34;, \u0026#34;wrapKey\u0026#34;, ] rotation_policy { automatic { time_before_expiry = \u0026#34;P30D\u0026#34; #ISO 8601 duration } expire_after = \u0026#34;P3Y\u0026#34; #ISO 8601 duration notify_before_expiry = \u0026#34;P29D\u0026#34; #ISO 8601 duration } } resource \u0026#34;azurerm_key_vault_key\u0026#34; \u0026#34;storage\u0026#34; { name = \u0026#34;project-storagekey-${var.environment}\u0026#34; key_vault_id = azurerm_key_vault.key.id key_type = \u0026#34;RSA\u0026#34; key_size = 2048 key_opts = [ \u0026#34;decrypt\u0026#34;, \u0026#34;encrypt\u0026#34;, \u0026#34;sign\u0026#34;, \u0026#34;unwrapKey\u0026#34;, \u0026#34;verify\u0026#34;, \u0026#34;wrapKey\u0026#34;, ] rotation_policy { automatic { time_before_expiry = \u0026#34;P30D\u0026#34; #ISO 8601 duration } expire_after = \u0026#34;P3Y\u0026#34; #ISO 8601 duration notify_before_expiry = \u0026#34;P29D\u0026#34; #ISO 8601 duration } } ","date":"28 June 2024","permalink":"/posts/tf_azure-3tier-post-2/","section":"Posts","summary":"IaC on 3-Tier architecture through Terraform in Azure","title":"IaC on 3-Tier architecture through Terraform in Azure - Part 2 Resource on Azure"},{"content":"Introduction # Welcome to Part 3 of our guide! In this section, we\u0026rsquo;ll focus on setting up essential components to handle data storage and database management. We\u0026rsquo;ll start with configuring an Azure Storage Account and its Blob Containers, ensuring secure access through network rules and data encryption. Next, we‚Äôll dive into setting up a MySQL database, including implementing a Private DNS Zone and private endpoints for enhanced security and isolation. By the end of this part, you\u0026rsquo;ll have a robust and secure foundation for managing your application‚Äôs data and databases efficiently.\nArchitecture # Creating Cloud Resource with Terraform # Storage # As mentioned before, storage will be created, to store content (eg. image, video) and log from MySQL server.\nStorage Account # Storage Account is created as Geo-redundant storage for this demo. It takes advantage as Azure will replicate your storage account synchronously across Azure availability zones and regions, enhanced data availability and improved data protection.\nWhen designing your storage account, data redundancy is often a critical business requirement. Factors such as consistency and cost play a key role in determining the best replication type for your scenario. For example, financial institutions often prefer Geo-Redundant Storage (GRS) to ensure maximum system reliability and data durability, as they handle sensitive data that requires strong disaster recovery capabilities. On the other hand, some local companies may opt for Locally Redundant Storage (LRS) or Zone-Redundant Storage (ZRS), as cost tends to be a more pressing concern for them.\nAs developers, it‚Äôs important to provide informed guidance to business users to ensure that technical solutions align with their needs. Always ensure the options you recommend fit the use case, and don‚Äôt forget to test and validate these choices. Be aware that not all redundancy types are available in every region‚ÄîGeo-Zone-Redundant Storage (GZRS), for instance, may not be supported every region.\nNote: Flag \u0026ldquo;account_replication_type\u0026rdquo; refers to Azure Storage redundancy. Valid options are LRS, GRS, RAGRS, ZRS, GZRS and RAGZRS. Please adjust the value according to your needs. For example, vaule \u0026ldquo;GRS\u0026rdquo; may be needed for production environment.\nNote: Infrastructure encryption is recommended for scenarios where doubly encrypting data is necessary for compliance requirements.\n# storage.tf # Storage Account resource \u0026#34;azurerm_storage_account\u0026#34; \u0026#34;project\u0026#34; { name = \u0026#34;project${var.environment}storage\u0026#34; resource_group_name = azurerm_resource_group.project.name location = azurerm_resource_group.project.location account_tier = \u0026#34;Standard\u0026#34; # refer to pricing tier, possible values are standard and premium account_replication_type = \u0026#34;ZRS\u0026#34; # Value changing may forces a new resource to be created infrastructure_encryption_enabled = \u0026#34;false\u0026#34; large_file_share_enabled = \u0026#34;false\u0026#34; public_network_access_enabled = \u0026#34;true\u0026#34; # public network access is enabled as for testing environment # Example to setup blob properties # blob_properties { # change_feed_enabled = \u0026#34;true\u0026#34; # last_access_time_enabled = \u0026#34;true\u0026#34; # versioning_enabled = \u0026#34;true\u0026#34; # delete_retention_policy { # days = 35 # } # restore_policy { # days = 30 # } # } identity { type = \u0026#34;SystemAssigned\u0026#34; # type of Managed Service Identity configured on Storage Account } lifecycle { ignore_changes = [ customer_managed_key # customer managed key will be manage in other teeraform resource ] } } Network Rules for Storage Account # Note: Only one azurerm_storage_account_network_rules can be tied to an azurerm_storage_account.\n# storage.tf # Network Rules for Storage Account resource \u0026#34;azurerm_storage_account_network_rules\u0026#34; \u0026#34;myipandsubnet\u0026#34; { storage_account_id = azurerm_storage_account.project.id default_action = \u0026#34;Deny\u0026#34; ip_rules = [\u0026#34;xxx.x.xxx.xxx\u0026#34;] # edit value to your home IP or whitelisted ip virtual_network_subnet_ids = [azurerm_subnet.storage_subnet.id, azurerm_subnet.db_subnet.id, azurerm_subnet.node_subnet.id] # subnet ids to secure the storage account bypass = [\u0026#34;Metrics\u0026#34;] } Data Encryption for Storage Account # Notes that resource \u0026ldquo;azurerm_storage_account\u0026rdquo; are ignoring changes in block \u0026ldquo;customer_managed_key\u0026rdquo; as we manage Customer Managed Key by resource \u0026ldquo;azurerm_storage_account_customer_managed_key\u0026rdquo;.\nNote: It\u0026rsquo;s possible to define a Customer Managed Key both within resource \u0026ldquo;azurerm_storage_account\u0026rdquo; via block \u0026ldquo;customer_managed_key\u0026rdquo; and by using the resource \u0026ldquo;azurerm_storage_account_customer_managed_key\u0026rdquo;. However it\u0026rsquo;s not possible to use both methods to manage a Customer Managed Key for a Storage Account, since there\u0026rsquo;ll be conflicts.\n# key.tf resource \u0026#34;azurerm_key_vault_access_policy\u0026#34; \u0026#34;storage\u0026#34; { key_vault_id = azurerm_key_vault.key.id tenant_id = data.azurerm_client_config.current.tenant_id object_id = azurerm_storage_account.project.identity.0.principal_id # Principal ID for the Service Principal associated with Identity of Storage Account secret_permissions = [\u0026#34;Get\u0026#34;] key_permissions = [\u0026#34;Get\u0026#34;, \u0026#34;Create\u0026#34;, \u0026#34;List\u0026#34;, \u0026#34;Restore\u0026#34;, \u0026#34;Recover\u0026#34;, \u0026#34;UnwrapKey\u0026#34;, \u0026#34;WrapKey\u0026#34;, \u0026#34;Purge\u0026#34;, \u0026#34;Encrypt\u0026#34;, \u0026#34;Decrypt\u0026#34;, \u0026#34;Sign\u0026#34;, \u0026#34;Verify\u0026#34;] } # storage.tf # Data Encrytion for Storage Account resource \u0026#34;azurerm_storage_account_customer_managed_key\u0026#34; \u0026#34;storage_key\u0026#34; { storage_account_id = azurerm_storage_account.project.id key_vault_id = azurerm_key_vault.key.id key_name = azurerm_key_vault_key.storage.name } Storage Blob Container # After all settings are created, we create Blob Container to storage files.\n# Storage Blob Container resource \u0026#34;azurerm_storage_container\u0026#34; \u0026#34;project\u0026#34; { name = \u0026#34;project-blob\u0026#34; storage_account_name = azurerm_storage_account.project.name container_access_type = \u0026#34;blob\u0026#34; } MySQL # For MySQL, we choose to provision MySQL Flexible Server (Azure Database for MySQL - Single Server is scheduled for retirement by September 16, 2024).\nNote: To learn difference between MySQL Single Server and MySQL Flexible Server, please refer to here.\nPrivate DNS Zone # We create Private DNS Zone for MySQL server to make sure database connects securely within our VNet.\n# private_dns.tf resource \u0026#34;azurerm_private_dns_zone\u0026#34; \u0026#34;database\u0026#34; { name = \u0026#34;project.${var.environment}.mysql.database.azure.com\u0026#34; resource_group_name = azurerm_resource_group.project.name } resource \u0026#34;azurerm_private_dns_zone_virtual_network_link\u0026#34; \u0026#34;db_links\u0026#34; { name = \u0026#34;${azurerm_virtual_network.project.name}-${var.environment}.com\u0026#34; private_dns_zone_name = azurerm_private_dns_zone.database.name resource_group_name = azurerm_resource_group.project.name virtual_network_id = azurerm_virtual_network.project.id } MySQL Database Server # Note that compute size \u0026ldquo;D2ads v5\u0026rdquo; is newly added in Region East Asia, pricing calculator isn\u0026rsquo;t updated on the choice of MySQL compute size when I used this size. The cost is USD 0.1420 on 6 Feb 2024. For more information, please refer to the compute size and cost.\nBy experience, I advise setting mode of block \u0026ldquo;high_availability\u0026rdquo; to \u0026ldquo;ZoneRedundant\u0026rdquo;. It can only be set before we create it. You CANNOT change HA mode to Zone-redundant if you created server with same-zone mode once.\nNote: Flag \u0026ldquo;private_dns_zone_id\u0026rdquo; is required when setting flag \u0026ldquo;delegated_subnet_id\u0026rdquo;. Private DNS zone should end with suffix \u0026lsquo;.mysql.database.azure\u0026rsquo;.com.\n# mysql.tf # MySQL Database Server resource \u0026#34;azurerm_mysql_flexible_server\u0026#34; \u0026#34;main\u0026#34; { name = \u0026#34;project-mysqlserver-${var.environment}\u0026#34; location = azurerm_resource_group.project.location resource_group_name = azurerm_resource_group.project.name delegated_subnet_id = azurerm_subnet.db_subnet.id # Changing value forces a new MySQL Flexible Server to be created private_dns_zone_id = azurerm_private_dns_zone.database.id zone = \u0026#34;1\u0026#34; administrator_login = \u0026#34;projectadmin\u0026#34; administrator_password = \u0026#34;xxxxxx\u0026#34; # change to your own password sku_name = \u0026#34;GP_Standard_D2ads_v5\u0026#34; # refer to SKU tier and compute size storage { size_gb = 20 auto_grow_enabled = true # must be \u0026#34;true\u0026#34; to enable `high_availability` } identity { type = \u0026#34;UserAssigned\u0026#34; identity_ids = [azurerm_user_assigned_identity.uai.id] # use created UAI as Service Identity } # Data Encrytion customer_managed_key { key_vault_key_id = azurerm_key_vault_key.db.id # set Encrytion key with created key primary_user_assigned_identity_id = azurerm_user_assigned_identity.uai.id } version = \u0026#34;5.7\u0026#34; # MySQL version, change to your own required version backup_retention_days = 30 # default 7 days high_availability { mode = \u0026#34;ZoneRedundant\u0026#34; # prefer set it to ZoneRedundant, mode can be change when you created server standby_availability_zone = 2 } tags = { Environment = \u0026#34;${var.environment}\u0026#34; } depends_on = [azurerm_private_dns_zone_virtual_network_link.db_links] lifecycle { ignore_changes = [ zone, high_availability.0.standby_availability_zone # avoid to migrate MySQL Flexible Server back to primary Availability Zone if a fail-over occured ] # prevent_destroy = true # prevent destroy for production environment } } Active Directory administrator # Here is an example to provide admin access to myself. The solution can be used to provide server admin access to corresponding team with UAI.\nresource \u0026#34;azurerm_mysql_flexible_server_active_directory_administrator\u0026#34; \u0026#34;me\u0026#34; { server_id = azurerm_mysql_flexible_server.main.id identity_id = azurerm_user_assigned_identity.prod.id login = \u0026#34;sqladmin\u0026#34; object_id = data.azurerm_client_config.current.client_id # myself tenant_id = data.azurerm_client_config.current.tenant_id # myself } Server Audit Log # We enable audit logs by updating server configurations. Audit log will be exported to Storage by updating Diagnostic Setting. Retention policy of audit log will be handled later.\nNote: Please refer to audit-logs and tutorial to learn more on audit log setting, including audit log events.\nNote: Feature \u0026ldquo;retention_policy\u0026rdquo; has been deprecated in favor of resource \u0026ldquo;azurerm_storage_management_policy\u0026rdquo;.\n# MySQL Database Server Parameters resource \u0026#34;azurerm_mysql_flexible_server_configuration\u0026#34; \u0026#34;audit_log_enabled\u0026#34; { name = \u0026#34;audit_log_enabled\u0026#34; resource_group_name = azurerm_resource_group.project.name server_name = azurerm_mysql_flexible_server.main.name value = \u0026#34;ON\u0026#34; # enable audit log } resource \u0026#34;azurerm_mysql_flexible_server_configuration\u0026#34; \u0026#34;audit_log_events\u0026#34; { name = \u0026#34;audit_log_events\u0026#34; resource_group_name = azurerm_resource_group.project.name server_name = azurerm_mysql_flexible_server.main.name value = \u0026#34;CONNECTION,GENERAL\u0026#34; # controls the events to be logged } # Example on setting MySQL users to be included for logging. # resource \u0026#34;azurerm_mysql_flexible_server_configuration\u0026#34; \u0026#34;audit_log_include_users\u0026#34; { # name = \u0026#34;audit_log_include_users\u0026#34; # resource_group_name = azurerm_resource_group.project.name # server_name = azurerm_mysql_flexible_server.main.name # value = \u0026#34;projectadmin\u0026#34; # } # MySQL Database Diagnostic Setting resource \u0026#34;azurerm_monitor_diagnostic_setting\u0026#34; \u0026#34;mysqlauditlog\u0026#34; { name = \u0026#34;mysqlauditlog\u0026#34; target_resource_id = azurerm_mysql_flexible_server.main.id storage_account_id = azurerm_storage_account.project.id # storage account that logs will be sent enabled_log { category = \u0026#34;MySqlAuditLogs\u0026#34; # possible values are \u0026#34;MySqlSlowLogs\u0026#34; and \u0026#34;MySqlAuditLogs\u0026#34; for MySQL flexible server retention_policy { enabled = false } } metric { category = \u0026#34;AllMetrics\u0026#34; enabled = false retention_policy { enabled = false } } depends_on = [ azurerm_mysql_flexible_server_configuration.audit_log_enabled, azurerm_mysql_flexible_server_configuration.audit_log_events ] } # Storage Lifecycle for MySQL Audit Log resource \u0026#34;azurerm_storage_management_policy\u0026#34; \u0026#34;project_mysql\u0026#34; { storage_account_id = azurerm_storage_account.project.id rule { name = \u0026#34;mysql-auditlog-lifecycle\u0026#34; enabled = true filters { prefix_match = [\u0026#34;am-containerlog/WorkspaceResourceId=/subscriptions\u0026#34;] blob_types = [\u0026#34;blockBlob\u0026#34;] } actions { base_blob { tier_to_cool_after_days_since_modification_greater_than = 30 tier_to_archive_after_days_since_modification_greater_than = 90 delete_after_days_since_modification_greater_than = 2555 } version { change_tier_to_archive_after_days_since_creation = 15 change_tier_to_cool_after_days_since_creation = 7 delete_after_days_since_creation = 30 } } } } MySQL Database # After all audit log settings are created, we create MySQL Database.\n# MySQL Database resource \u0026#34;azurerm_mysql_flexible_database\u0026#34; \u0026#34;project\u0026#34; { name = \u0026#34;project-mysqldb-${var.environment}\u0026#34; resource_group_name = azurerm_resource_group.project.name server_name = azurerm_mysql_flexible_server.main.name charset = \u0026#34;utf8mb4\u0026#34; collation = \u0026#34;utf8mb4_unicode_ci\u0026#34; } ","date":"28 June 2024","permalink":"/posts/tf_azure-3tier-post-3/","section":"Posts","summary":"IaC on 3-Tier architecture through Terraform in Azure","title":"IaC on 3-Tier architecture through Terraform in Azure - Part 3 Resource on Azure"},{"content":"","date":"28 June 2024","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":"","date":"28 June 2024","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"28 June 2024","permalink":"/tags/terraform/","section":"Tags","summary":"","title":"Terraform"},{"content":" HelloWorld! Welcome to Marco\u0026rsquo;s blog! With this blog,I will share my experience on several cloud engineering solutions or DevOps solution, including IaC on Azure, AWS, and GCP, python function Lambda and workflow on GCP, build cicd pipeline etc. Enjoy!\n","date":"28 June 2024","permalink":"/","section":"Welcome to my blog! üéâ","summary":"HelloWorld!","title":"Welcome to my blog! üéâ"},{"content":"Introduction # Hello everyone! In this article, I will show you how to provision cloud resources for a 3-tier architecture through IaC by Terraform and deploy the application in Kubernetes(AKS).\nTerraform as a cornerstone in IaC, revolutionizes modern IT practices, offering unparalleled benefits for reliability and agility. Notably, Terraform sets itself apart by being cloud-agnostic, allowing for the seamless integration of multiple providers and services, and creating a comprehensive representation and management of the entire infrastructure ecosystem and its associated services.\nWith my experience in cloud architecture, I will demonstrate and explain all processes from provisioning cloud infrastructure to application deployment. Assuming our customer has DevOps Team to handle operational workloads and will deploy monitoring tools to observe the performance of their applications, we deploy Kubernetes service instead of container service, to provide more control and flexibility.\nIn this blog, we will first go through all the steps on how we provision cloud infrastructure in Azure by Terraform with well-designed cloud strategy, from considering aspects of security, data protection, monitoring, etc. So, let\u0026rsquo;s get started!\nFor more information on Terraform, please refer to Terraform and Azure Provider for information and documents.\nArchitecture # Before you begin # To complete this document you need the following resources:\nAzure Account Azure Service Principal To create Azure Account and Service Principal, please refer to Azure Account and Azure Service Principal.\nNote: The whole demonstration will run in bash, Azzure CLI, and TF code for further CICD.\nSet up TF project # Terraform State # The first step in Terraform is to set up the location of the state file.\nTerraform creates a state file called ‚Äúterraform.tfstate.‚Äù This file tracks the current state of your infrastructure and resources, enabling Terraform to manage and update them as needed.\nBy default, the state file is saved locally inside the Terraform project directory, making it accessible only to the individual working on the project.\nExample image from spacelift - tfstate in local directory, Management on Terraform State # According to AWS, the recommended practice for managing state files is to use Terraform\u0026rsquo;s built-in support for remote backends.\nIn a development project where multiple people need to access the state file, it should be kept in a durable and scalable environment. A shared storage system effectively meets these requirements.\nFor our demonstration, we have chosen Azure Blob Storage as the backend for Terraform.\nAzure Blob Storage provides server-side encryption to protect your data, preventing unauthorized access and safeguarding sensitive information. Create Azure Blob Storage # Before you create blob storage, sign in with Azure CLI.\nAPPID=\u0026#34;\u0026lt;app-id\u0026gt;\u0026#34; SPPASSWORD=\u0026#34;\u0026lt;password-or-cert\u0026gt;\u0026#34; SPTENANT=\u0026#34;\u0026lt;tenant\u0026gt;\u0026#34; # Login with service-principal az login --service-principal -u $APPID -p $SPPASSWORD --tenant $SPTENANT Then, run Azure CLI to create resource group, storage account and blob container for storing tf state.\n#!/bin/bash RESOURCE_GROUP_NAME=\u0026#34;project-tfstate\u0026#34; STORAGE_ACCOUNT_NAME=\u0026#34;project-tfstate-sa\u0026#34; CONTAINER_NAME=\u0026#34;project-tfstate-sa-blob\u0026#34; PUBLIC_IP=\u0026#34;16.17.18.0/24\u0026#34; ##Example # Create resource group az group create --name $RESOURCE_GROUP_NAME --location eastus We create storage account with enabled Infrastructure encryption as 1st-layer encryption.\nMoreover, we block public network access and add a network rule to only allow configuring access from our on-premises network.\n# Create storage account az storage account create --resource-group $RESOURCE_GROUP_NAME\\ --name $STORAGE_ACCOUNT_NAME --sku Standard_LRS\\ --encryption-services blob\\ --kind StorageV2 --allow-blob-public-access false\\ --require-infrastructure-encryption # Add a network rule for an IP address range to Storage Account az storage account network-rule add --resource-group $RESOURCE_GROUP_NAME\\ --account-name $STORAGE_ACCOUNT_NAME --ip-address $PUBLIC_IP # Create blob container az storage container create --name $CONTAINER_NAME\\ --account-name $STORAGE_ACCOUNT_NAME Infrastructure encryption can be enabled for the entire storage account, or for an encryption scope within an account. Detail for Storage Account will be explained in section for storage. Create Terraform State # We define backend in configuration to create Azure Blob Storage backend.\nNote: We use the name of Storage Account, resource group, and blob storage created in the pervious step as variables in those configurations.\n# provider.tf terraform { backend \u0026#34;azurerm\u0026#34; { resource_group_name = \u0026#34;project-tfstate\u0026#34; storage_account_name = \u0026#34;project-tfstate-sa\u0026#34; container_name = \u0026#34;project-tfstate-sa-blob\u0026#34; key = \u0026#34;demo.terraform.tfstate\u0026#34; } } Provider Configuration # Terraform relies on plugins called providers to interact with cloud providers, SaaS providers, and other APIs. Thus, we add provider \u0026ldquo;azurerm\u0026rdquo; for Terraform to interact with Azure.\nSpecify the version on provider as for provider versioning, and avoid accidental upgrades to incompatible new versions. # provider.tf terraform { required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;=3.79.0\u0026#34; } } backend \u0026#34;azurerm\u0026#34; { .... } } # Configure the Azure provider provider \u0026#34;azurerm\u0026#34; { features { key_vault { purge_soft_delete_on_destroy = true recover_soft_deleted_key_vaults = true } } storage_use_azuread = true skip_provider_registration = true } Terraform Basic CLI # While writing terraform code, we have a basic workflow to provision resources. Furthermore, we can also run the workflow for script testing to make sure resources can be deployed. Refer to tutorial from Terraform, 3 core steps should be run to deploy your Terraform code:\nInitialize prepares your workspace so Terraform can apply your configuration. Plan allows you to preview the changes Terraform will make before you apply them. Apply makes the changes defined by your plan to create, update, or destroy resources. Note: Details of command options can refer to Terraform command document.\nInitialize # Initialize the Terraform configuration to install the required providers. Whenever you add a new provider or module to your configuration or tests, you must run the terraform init command.\nExample with options:\n# Don\u0026#39;t hold a state lock during backend migration. terraform init -lock=false # Reconfigure a backend, and attempt to migrate any existing state. terraform init -migrate-state # Reconfigure a backend, ignoring any saved configuration. terraform -reconfigure # Configuration to be merged with what is in the configuration file\u0026#39;s \u0026#39;backend\u0026#39; block. terraform -backend-config=path Plan # When you run the terraform plan command, Terraform generates a plan by comparing your current configuration to the existing state of your infrastructure. The plan categorizes changes into three types: create, update, or destroy resources. Here are some examples with options:\n# Load variable values from the specified file. terraform plan -var-file=filename # Set a value for an input variable in the root module of the configuration. terraform plan -var \u0026#39;foo=bar\u0026#39; # Create a plan to destroy all objects currently managed by this Terraform configuration. terraform plan -destroy # Check whether remote objects still match the most recent Terraform apply, without proposing any actions to undo changes made outside of Terraform. terraform plan -refresh-only # Write the generated plan to the specified file in an opaque format, which can later be passed to \u0026#39;terraform apply\u0026#39; to execute the planned changes. terraform plan -out=FILENAME Developers can use the terraform plan command to preview the results and impact of code changes. Furthermore, the \u0026rsquo;-out\u0026rsquo; flag is commonly used in CI/CD processes. It ensures consistent results when separating the \u0026ldquo;plan\u0026rdquo; and \u0026ldquo;apply\u0026rdquo; stages in deployment. It is recommended to name the plan file \u0026ldquo;tfplan\u0026rdquo;.\nBe cautious with the \u0026lsquo;destroy\u0026rsquo; type, as cloud resources will be destroyed once you run the \u0026lsquo;apply\u0026rsquo; command. Apply # The terraform apply command assesses the current infrastructure state, identifies discrepancies, and adjusts resources by creating, updating, or deleting them as needed.\nTypically, when this command is run without any options, Terraform will execute a terraform plan, present the user with the proposed changes or impacts, and then prompt for confirmation before proceeding with the execution.\nExample with options:\n# Load variable values from the specified file. terraform apply -var-file=filename # Set a value for an input variable in the root module of the configuration. terraform apply -var \u0026#39;foo=bar\u0026#39; # Destroy all objects currently managed by this Terraform configuration. terraform apply -destroy # Automatically applies all changes and impacts without prompting you for confirmation. terraform apply -auto-approve # takes the actions in the saved plan without prompting you for confirmation. terraform apply [plan file] # Apply changes only on targeted resource terraform apply -target=‚Äùmodule.vnet.0\u0026#34; For a two-step workflow in CI/CD, you can use either the \u0026rsquo;-auto-approve\u0026rsquo; flag or pass a previously saved plan file. However, note that the \u0026rsquo;-auto-approve\u0026rsquo; flag will be ignored when a plan file is passed because Terraform treats the plan file as the approval and will not prompt for confirmation in that case.\nBe cautious with the \u0026lsquo;destroy\u0026rsquo; type, as cloud resources will be destroyed once you run the \u0026lsquo;apply\u0026rsquo; command. ","date":"27 June 2024","permalink":"/posts/tf_azure-3tier-post-1-setup/","section":"Posts","summary":"IaC on 3-Tier architecture through Terraform in Azure","title":"IaC on 3-Tier architecture through Terraform in Azure - Part 1 Prerequisite"},{"content":"What I do In my role as a Cloud Engineer, I am deeply engaged in crafting robust cloud architectures and implementing efficient DevOps practices. My journey in Cloud Engineering is driven by a passion for leveraging technology to optimize business operations and drive growth. Under the mentorship of Jam at Green Tomato, I\u0026rsquo;ve honed my expertise in designing scalable cloud solutions that align with strategic business objectives. Effective collaboration and communication with cross-functional teams are integral to my approach, ensuring seamless deployment and management of cloud infrastructures. I am dedicated to continuous learning and innovation, staying abreast of industry trends to deliver cutting-edge solutions that meet evolving business needs.\nLearn to be a better ITer Recently, I earned the Azure Administrator Associate certification (AZ-104), showing my skills in managing Azure environments. Looking ahead, I\u0026rsquo;m eager to pursue certifications in Certified Kubernetes Administrator and either Azure or AWS professional solution architect for my next steps, aiming to broaden my skill set and stay at the forefront of industry trends.\nTarget As I continue to grow in my career, I am excited about the opportunity to contribute my skills in cloud architecture, DevOps practices, and continuous improvement to a new team. I believe in the transformative potential of cloud technologies and am committed to delivering solutions that drive business growth and innovation.\nMeet Marco Hello! I‚Äôm Marco, a passionate Cloud DevOps Engineer from Hong Kong. Alongside my professional pursuits, I‚Äôm a dedicated cat person with three adorable companions: BB, Chacha, and Makmak. They bring endless joy to my life. When I‚Äôm not working or spending time with my cats, I enjoy playing squash and am currently looking for a squash club to join. Staying active and connected with others is important to me, both personally and professionally.\nPrevious Nextsads ","date":"13 June 2022","permalink":"/about/","section":"Welcome to my blog! üéâ","summary":"What I do In my role as a Cloud Engineer, I am deeply engaged in crafting robust cloud architectures and implementing efficient DevOps practices.","title":"About"},{"content":" ","date":"13 June 2022","permalink":"/posts/","section":"Posts","summary":" ","title":"Posts"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/topics/","section":"Topics","summary":"","title":"Topics"}]